## 0) THE DATA :
Which table are we using?
What I've understood is that we should aggregate all the first columns of processed files, what do you think?





## 1) REMOVE DATA :
Here is my idea. We are not supposed to be "memory pigs" so we should do it in one go.

Calculate the total number of points : num_total = number_lines * number_columns.
Calculate the number of points to remove : num_remove = percentage / 100 * num_total
I found a magic function : random.sample. We can call random.sample(range(num_total),num_remove).
This will create a list with the positions we are going to delete.


# NAME OF THE FILE :
erase.py


# PSEUDO CODE FOR DELETING NUMBERS
Randomly choose which points to erase
Iterate through the file, for each line :
	If there is any number to erase, do it
	Write back in the new file


# COMPLEXITY
O(m*n) where m is the number of rows and n the number of columns


# NOTES
09/11 : Paul : The function is implemented in erase.py. The input file must be a file with a header (1st line) and with the column having the identifier, typically those found in the directory "E-GEOD-10590.processed.1". To what I've tried, it is working. It maybe needs some error handling






## 2) IMPLEMENT K-NN :
# NAME OF THE FILE :
knn.py


# PSEUDO CODE :
a) A function to write a read the matrix from a file
b) A function to write a matrix to a file
c) A function for euclidian distance. It is adapted to our case to consider NAs.
d) A function for weights used for computing the average.
e) The knn function

# COMPLEXITY
O(m²*n²) is the worst case, ie if all rows are missing at least 1 number and if we compare all rows against all others for every imputation.


# NOTES
13/11 : Paul : The function seems to work. Took 52 minutes for the test3.txt file (32800 * 8 matrix with 10%NA). Maybe we can enhance it by rounding numbers but for complexity I don't really know. For evaluation, we could try to use a smaller dataset (10 000 points instead of 32 800 would theoretically divide the running time by 10).
22/11 : Paul : round numbers in the KNN
22/11 : After changing an error in the code, it now runs in 32min for k = 12 and missing = 10%

